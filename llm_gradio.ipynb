{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les Misérables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llm 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatMessagePromptTemplate,ChatPromptTemplate,SystemMessagePromptTemplate,HumanMessagePromptTemplate,MessagesPlaceholder\n",
    "from langchain import LLMChain\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = ChatOllama(model='llama3.1:latest')\n",
    "#response_llm = llm_model.invoke(\"Hello, how can I help you today?\")\n",
    "#print(response_llm.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = ChatOpenAI(model_name=\"gpt-4\")\n",
    "#response_gpt = gpt_model.invoke(\"Hello, how can I help you today?\")\n",
    "#print(response_gpt.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. llm 모델 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 프롬프트 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "    너는 책을 읽어주는 어시스턴트야. 아래 지침에 따라 답변을 해줘야 해.\n",
    "    모든 출력은 한국어로 해야 해.\n",
    "    \n",
    "    1. 사용자가 txt 파일을 제공하면, 해당 내용을 문단별로 출력해야 해.\n",
    "    2. 사용자가 '다음'이라는 질문({question})을 하면, 다음 문단을 출력해야 해.\n",
    "    3. txt 파일을 처음 받으면, {context_character}의 말투를 참고하여 등장인물처럼 대화해야 해.\n",
    "    4. 문단 중에 \" \", ' ' 와 같은 대화문이 나오면, 대화문 뒤에 : {emotion}을 함께 출력해야 해.\n",
    "    5. 사용자가 책의 내용에 대해 질문({question})을 하면, 등장인물의 말투로 {context_books}를 참고하여 답변해야 해.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        MessagesPlaceholder(variable_name=\"history\"), # 이전 대화 내용 저장용\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "output_parser= StrOutputParser()#글자만 가져온다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 대화 내용을 기억하는 llm 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이죠, 첫 문단을 읽어드리겠습니다.\n",
      "\n",
      "\"어느 날, 한 소년이 집을 나서 그가 사랑하던 소녀를 만나러 가기로 했다. 그 소년의 이름은 밥이었다. 밥은 세상에서 가장 사랑스러운 소녀를 만나러 가는 길에 매우 행복했다. 그는 그녀에게 자신의 사랑을 고백할 계획이었다.\"\n"
     ]
    }
   ],
   "source": [
    "# 대화 메모리 생성 (대화 히스토리를 관리)\n",
    "conversation_memory = ConversationBufferMemory()\n",
    "\n",
    "\n",
    "# LLMChain 생성: 프롬프트와 LLM을 연결\n",
    "llm_chain = LLMChain(\n",
    "    llm=gpt_model,\n",
    "    prompt=chat_prompt,\n",
    ")\n",
    "\n",
    "# 사용자 질문 처리 및 답변 생성 함수\n",
    "def handle_user_input(user_input, history=[], context_books=\"책 내용 예시\", context_character=\"주인공\", emotion=\"감정 예시\", question=\"질문 예시\"):\n",
    "    # 히스토리 업데이트\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 모델 실행 및 답변 생성\n",
    "    response = llm_chain.run({\n",
    "        \"history\": history,\n",
    "        \"input\": user_input,\n",
    "        \"context_books\": context_books,\n",
    "        \"context_character\": context_character,\n",
    "        \"emotion\": emotion,\n",
    "        \"question\": question\n",
    "    })\n",
    "    \n",
    "    # 히스토리에 응답 추가\n",
    "    history.append({\"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "    return response, history\n",
    "\n",
    "# 예시 실행\n",
    "user_input = \"첫 문단을 읽어줘\"\n",
    "history = []\n",
    "response, history = handle_user_input(user_input, history)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 텍스트 벡터화 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 챗봇 ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 업로드 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 업로드 처리 함수\n",
    "# 이거 수정해서 벡터화 및 파일 db 생성해서 순서대로 부르게 하기\n",
    "# gpt 보라\n",
    "def chatbot_send_file(chat_history, file):\n",
    "    if file is not None:\n",
    "        with open(file.name, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        paragraphs = content.split('\\n\\n')  # 문단별로 분리\n",
    "        ai_text = \"\\n\\n\".join(paragraphs)  # 문단을 다시 합쳐서 출력\n",
    "        chat_history.append([\"사용자가 업로드한 파일입니다.\", ai_text])\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이벤트 처리 함수\n",
    "def chatbot_send_message(chat_history, text):\n",
    "    ai_text = llm_chain.invoke(text)  # 여기에 챗봇 처리 로직 추가\n",
    "    chat_history.append([text, ai_text])\n",
    "    return chat_history, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "IMPORTANT: You are using gradio version 3.48.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Tab(\"음성 인식봇\"):\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\n",
    "                value=\"\"\"\n",
    "<center><h1> 음성 인식 봇 </h1></center>\n",
    "<center> AI 인공지능 봇입니다. 음성으로 묻거나 문서 요약, 일정 관리 등을 할 수 있습니다.</center>\n",
    "\"\"\"\n",
    "            )\n",
    "            cb_chatbot = gr.Chatbot(\n",
    "                value=[[None, \"안녕하세요 AI 챗봇입니다. 무엇이든 질문하세요\"],\n",
    "                       ['나는 지금 배가 고파요', '배가 고프시군요 메뉴를 추천해드릴까요?']\n",
    "                       ],\n",
    "                label=\"구미챗봇\",\n",
    "            )\n",
    "        with gr.Row():\n",
    "            cb_textbox = gr.Textbox(\n",
    "                lines=3,\n",
    "                placeholder=\"입력창입니다.\",\n",
    "                container=False,\n",
    "                scale=7\n",
    "            ) # 채팅 입력\n",
    "\n",
    "            gr.Audio(\n",
    "                format=\"mp3\",\n",
    "                scale=1,\n",
    "                min_width=200,\n",
    "                label=\"음성을 입력해주세요\"\n",
    "            ) # 음성 입력\n",
    "\n",
    "            cb_send_btn = gr.Button(\n",
    "                value=\"보내기\",\n",
    "                visible=\"primary\",\n",
    "                scale=1\n",
    "            ) # 실행 버튼\n",
    "            \n",
    "            file_upload = gr.File(\n",
    "                label=\"txt 파일을 업로드해주세요\",\n",
    "                type=\"file\"\n",
    "            ) # 파일 업로드\n",
    "\n",
    "        with gr.Row():\n",
    "            gr.Button(\n",
    "                value=\"되돌리기\"\n",
    "            )\n",
    "            gr.Button(\n",
    "                value=\"초기화\"\n",
    "            )\n",
    "        \n",
    "        # 텍스트 입력 처리\n",
    "        cb_send_btn.click(\n",
    "            fn=chatbot_send_message,\n",
    "            inputs=[cb_chatbot, cb_textbox],\n",
    "            outputs=[cb_chatbot, cb_textbox]\n",
    "        )\n",
    "        \n",
    "        # 파일 업로드 처리\n",
    "        file_upload.change(\n",
    "            fn=chatbot_send_file,\n",
    "            inputs=[cb_chatbot, file_upload],\n",
    "            outputs=[cb_chatbot]\n",
    "        )\n",
    "\n",
    "    with gr.Tab(\"문서 요약봇\"):\n",
    "        pass\n",
    "    with gr.Tab(\"일정 관리봇\"):\n",
    "        pass\n",
    "\n",
    "app.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gumi_env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
